
<!DOCTYPE html>
<html lang="en">

<head>
    <title>Sushobhan Parajuli</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Overpass+Mono:wght@300;400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
</head>
<body>
    <header class="site-header">
        <nav class="nav">
            <div class="container flex-wrap">
                <h1 class="logo">
                    <a href="https://sushobhan55.github.io">Sushobhan Parajuli</a>
                </h1>
                <ul class="navbar">
                    <li><a href="index.html">About</a></li>
                    <li><a href="blog.html">Blog</a></li>
                    <li><a href="apps.html">Apps</a></li>
                    <li><a href="https://theticker.org/author/sushobhanparajuli/" target="_blank">The Ticker</a></li>
                    <li><a href="photography.html">Photography</a></li>
                </ul>
            </div>
        </nav>
    </header>
    
<article class="page container">

  <div id="blog-list">
    <h3>Blog Posts:</h3>
  <ul>
    <li><a href="#blog4">Benford's Law in Stock Returns</a></li>
    <li><a href="#blog3">Time Travel Made Possible with AI</a></li>
    <li><a href="#blog2">Portfolio Optimization with Python</a></li>
    <li><a href="#blog1">Fine-tuning a LLM to Build a Customized Chatbot</a></li>
  </ul>
  </div>
    
    <article class="page container">
      <div class="page-content">
      <div class="blog-post">

    <div id="blog4">
        <div class="blog-heading">Benford's Law in Stock Returns</div>
        <p>October 2, 2023</p>
        <p><strong>"Financial data is definitely not uniform. A lot of financial data conforms to Benford's law, which says that in some types of real-world data, the lead digits are not equally likely."</strong>
        <div align="right"><img src="images/humblepi.png" alt="Humble Pi" height="40%" width="20%"></div></p>
        <p>While reading Matt Parker's book "Humble Pi" in Chapter 12, I came across Parker's mention of how financial data are not uniform, and many of them follow Benford's Law. This got me curious, so I decided to check if this is true by looking at data about stock returns.</p>
        <strong>Benford's Law</strong>
        <p>Benford's Law is an observation where in many naturally occurring datasets, the first digit of numbers is more likely to be small (1, 2, 3, etc.) rather than large (9). Benford's Law is utilized in various fields, including accounting fraud detection, the analysis of election data, the detection of scientific fraud, and the examination of macroeconomic data.</p>
        <strong>Stock Returns Data</strong>
        <p>I retrieved price data for the S&P 500 index from Yahoo! Finance, spanning from the beginning of the year 2000 up to the present day. Then I calculated the daily logarithmic returns. Logarithmic returns offer a more accurate measure of the percentage change in the stock market over a period of time. I got rid of rows with zero(3) and missing(1) returns. Then I multiplied entire logarithmic returns data by 1,000,000 to resize the lowest return value. Because some returns are negative, I calculated absolute values of the returns and then extracted the lead digits for each absolute values and stored in a new column.</p>
            <div align="center">
                <img style="max-width: 100%;" src="images/data.png" alt="Data" height="auto">
            </div>
        <div align="center"><p><a href="https://github.com/Sushobhan55/Benfords_Law/blob/main/benfords_law.ipynb">Click here for the code.</a></p></div>
        <strong>Benford Percentages</strong>
        <p>The next step was to calculate and compare the frequency of each lead digit, in percentage, with the benford percentages. Benford's percentages are as follows: 30.1%, 17.6%, 12.5%, 9.7%, 7.9%, 6.7%, 5.8%, 5.1%, and 4.6%, each corresponding to the first digits 1 through 9, respectively.</p>
        <strong>Plot: Observed vs. Benford's Law</strong>
            <div align="center">
                <img style="max-width: 100%;" src="images/graph.png" alt="Graph" height="auto">
            </div>
        <p>After plotting a graph for Observed vs. Benford's Law, it was noticed that the frequency of lead digits of scaled absolute returns for S&P 500 index somewhat mimics Benford's Law, with the data following a similar pattern as in Benford's Law.</p>
    </div>
          
   <hr> 
         
    <div id="blog3">
        <div class="blog-heading">Time Travel Made Possible with AI</div>
          <p>June 14, 2023</p>
          <p>Last summer, while leisurely walking through Central Park's gentle hills, a captivating idea sparked my imagination. With a profound interest in history and geography, I couldn't help but imagine the possibilities. It all began when Zack, my data science instructor from CUNY Tech Prep, introduced me to GPT-3 and recommended an enlightening podcast episode titled "The Ghost in the Machine" by This American Life. The episode featured a writer utilizing GPT-3 to evoke the writings of her late sister. Back then, before the pervasive presence of ChatGPT, this particular episode aroused my curiosity.</p>
          <p>To add to the mix, I had recently watched Martin Scorsese's masterpiece, "The Gangs of New York", which I revisited more than once. As I wandered through the park, an idea began to take shape in my mind— a virtual world where historical maps and places came alive, populated by the spirits of the past.  With each step I took on the streets of Manhattan, I envisioned the prospect of witnessing ancient New York City in its full splendor. Imagining chance encounters with ordinary citizens from Five Points in the 1840s, engaging in open conversations that traversed time. Alternatively, stumbling upon Walt Whitman in a dimly lit tavern in downtown Brooklyn, and sharing my profound admiration for "Crossing Brooklyn Ferry". Perhaps, in this imagined realm, our encounter even inspired Whitman to pen this magnificent poem. Of course, such musings were in jest. Imagine the possibility of conversing with John Pierpont Morgan, exchanging insights about the world of banking and advising to reconsider his investment in Titanic ship. Envision meeting Hamilton and beseeching him to reconsider his fateful duel with Burr. The realm of possibilities was boundless.</p>
            <div align="center">
                <img style="max-width: 100%;" src="images/ai_nyc_1920s.jpg" alt="AI generated NYC in 1920s" height="auto">
                <p><u>Prompt: Rush hour in the 1920s NYC.</u></p>
            </div>
        <p>This concept further fueled my imagination and led me to ponder the practicality of turning this vision into reality. At the time, the buzz surrounding virtual reality held great promise, leading me to believe that ancient New York City could be meticulously recreated through the clever integration of technology. But I didn't want to stop there. I envisioned the creation of other historical locations across various time periods, meticulously designed and populated with lifelike characters. Large language models (LLMs) could be leveraged to personalize these characters through fine tuning on their writings – or the kind of writings they could have written – from the past, and carefully crafted prompts. This immersive journey into the past holds potential for an exceptional blend of education and entertainment.</p>
        <p>Today, we witness the rise of numerous startup companies harnessing the capabilities of large language models. Enterprises such as Character.AI have focused on crafting personalized characters driven by these models, although they have not yet ventured into recreating historical figures. Some companies in the gaming industry, like Didimo, offer a text-to-3D generator that outputs editable game characters. Initially, my vision centered around incorporating such historical characters into a three-dimensional virtual world, meticulously set in historical locales. However, recent times have seen augmented reality surpass virtual reality in popularity. While virtual reality completely replaces our vision with an immersive experience, augmented reality enriches our reality by integrating virtual elements. While virtual reality can offer an unparalleled journey into the past, augmented reality provides the means to bring forth deceased individuals, powered by LLMs, into our present world.</p>
        <p>I don’t want to stop here. Imagine this: we could save ourselves as data, so that future generations can play with us even when we're pushing up daisies. And guess what those tech giants with access to our social media might do? Turn us into their very own Ghosts in the Machine. How spooky, yet amusing, to be digital puppets for their entertainment!</p>
     </div>
          
   <hr> 
          
     <div id="blog2">   
          <p><div class="blog-heading">Portfolio Optimization with Python</div>
          <p>June 3, 2023</p>
          <strong><p>Efficient Frontier</strong>
          <p>Efficient frontier is a set of optimal portfolios that offer the highest expected return for a given level of risk or lowest risk for a given level of expected return. Portfolio’s expected return is the sum of each product of an individual asset’s expected return with its respective weight in the overall portfolio.
          <p>Rp = ∑(Wi * Ri), where Rp = portfolio expected return,
                                     <p>Wi = weight of an individual asset, 
                                     <p>Ri = expected return of an individual asset.
          <p>Portfolio’s risk is gauged by its standard deviation, which is the square root of variance. Variance is a function of weights, variance and covariance. It is expressed as a dot product of matrices: 
              <p>σ2 = Wᵀ . V . W, where V = variance-covariance matrix,<p>W = matrix of individual asset weight,<p>Wᵀ = transpose of W.
          <strong><p>Stock Portfolio</strong> 
             <p>In python, I picked 20 different stocks across different industries to comprise a portfolio using <code>pandas_datareader</code>. Initially, I assigned 5% weight to each stock in order to observe the expected annual return and annual volatility of the portfolio without optimization. Then I calculated returns on each stock. Finally, I used the above formula (Rp) to calculate the annual portfolio return. Backtesting was done on the past five years of stock price data. I calculated the annual variance-covariance matrix with an account that a typical year has 252 trading days. Then I used the above variance formula to calculate the portfolio’s variance, followed by its standard deviation.
             <p>The result was an expected annual return of <strong>34.0%</strong> and annual risk/volatility of 22.0%. This return and risk composition is suboptimal, and the initial portfolio is one of many suboptimal portfolios that lie below the efficient frontier. 
           <div align="center">
              <img style="max-width: 100%;" src="images/EF.jpg" alt="Efficient Frontier" height="auto">
           </div>
          <strong><p>Optimization with Python</strong>
           <p>I used <code>PyPortfolioOpt</code> to import <code>EfficientFrontier, risk_models, expected_returns, and objective_functions</code>. There is a detailed explanation of this package in its <a href="https://pyportfolioopt.readthedocs.io/en/latest/">documentation</a>. I calculated the expected return of the portfolio and the annualized sample covariance matrix of individual returns using the imported libraries. 
           <p>The next step was to optimize the Sharpe ratio. <strong>Sharpe ratio</strong> is the difference between the returns of the investment and the risk-free return, divided by the standard deviation of the investment. The higher sharpe ratio means that the return/risk relationship is more optimal.
           <p>In order to avoid many negligible positions, I set the parameter gamma more than 1 by using <code>objective_functions</code>. Higher gamma diversifies the portfolio. I cleaned the weights to get rid of non essential decimal digits.
          <div align="center"><p><a href="https://github.com/Sushobhan55/Algo/blob/master/Portfolio%20Optimizer.ipynb">Click here for the code.</a></p></div>
          <strong><p>Results</strong>
          <p>I was able to optimize my portfolio with an expected annual return <strong>59.1%</strong> for an annual volatility of 28.3%. The sharpe ratio was 2.02, which is a good measure. 
                <p>Discrete allocation of each stock was calculated by using individual weights of the optimized portfolio and an imaginative $1,000,000 portfolio amount.
          <strong><p>Implementation</strong>
                <p>An investor can implement this strategy to gain higher returns on their investments. They can customize the backtesting period, their portfolio stocks, and portfolio amount and finally get the discrete allocation of stocks in the optimized portfolio. I did the same with my portfolio in an investment challenge, and the result was impressive.
      </div>
          
   <hr>
          
      <div id="blog1">
        <p><div class="blog-heading">Fine-tuning a LLM to Build a Customized Chatbot</div>
          <p>August 22, 2022</p>
          <p>A large language model(LLM) is a deep learning model trained on enormous text data available on the internet. LLMs are a remarkable development in the field of Natural Language Processing as they are capable of language understanding and generation. Given a sequence of text, a LLM understands it and predicts the next token in the sequence. It uses an attention mechanism that allows it to highlight the most relevant information of the input text, and that’s how it understands the text. Then the model calculates probabilities of occurrence of different tokens that could follow the input sequence, and generates the token with the highest probability. A token can be a word or a character.
          <p>Some of the examples of LLMs are ELMo, Turing-NLG, Generative Pre-trained Transformer (GPT, GPT-2, and GPT-3), BERT, RoBERTa, and so on. These are very large and computationally expensive machine learning models and are developed by corporations and research groups. An individual may not build such a powerful model on their own, however they can fine-tune them on their data to get a desired model. One can fine-tune these pre-trained models on specific data to perform a downstream task, a task that you want to solve. Fine-tuning refers to re-training the pre-trained model on a custom data.
            <div align="center">
            <video width="500" height="300" autoplay muted>
                <source src="images/demo.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <p><a href="https://github.com/Sushobhan55/Peterson-Bot">Click for the github repository.</a>
            </div>
          <p>I built a chatbot that imitates Jordan Peterson. First, I created a dataset pretending I was talking to him and his responses are his actual words from either quora answers or interview transcripts. My responses are relevant to his responses and thus it builds up as a conversation. The dataset has in total 761 text messages, which is a small size data.
          <p>Next, I fine-tuned DialoGPT on the above dataset. DialoGPT is GPT-2 fine-tuned on conversation data. DialoGPT is an example of fine-tuned LLM to attain a downstream task, to serve as a conversational chatbot. Further fine-tuning on the above dataset makes it chat like Jordan Peterson.
          <p>Fine-tuning a pre-trained model works fine to make LLMs perform downstream tasks; however, if the data is large, it faces the same problem of being computationally expensive like training a new model. Recently, researchers have found that <a href="https://arxiv.org/pdf/2111.01998.pdf">prompt learning</a> is very effective in attaining downstream tasks, especially if it requires small data size. Prompt learning is a paradigm of providing LLMs with a carefully designed prompt, for example – descriptions of a task, so it performs that specific task.
     </div>
          
   <hr>       
              
      </div>
      </div>
    </article>
    <p>
    <p>
    
    <footer class="site-footer">
        <div class="container">
            <small>
                    <b>Last Updated:</b> Jun 14, 2023
                </small>
            <small class="block">
                    © 2023 Sushobhan Parajuli · &lt;/&gt; Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> and <a href="https://github.com/heiswayi/thinkspace" target="_blank">Thinkspace</a>; hosted on <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.
                </small>
        </div>
    </footer>
</body>
</html>
